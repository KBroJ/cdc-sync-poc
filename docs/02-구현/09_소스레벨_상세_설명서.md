# CDC PoC 소스레벨 상세 설명서

> 이 문서는 CDC PoC의 모든 구성요소를 **왜 이렇게 만들었는지**, **각 설정이 무슨 의미인지** 소스 레벨에서 상세히 설명합니다.

---

## 목차

1. [CDC 개념 이해](#1-cdc-개념-이해)
2. [전체 아키텍처 흐름](#2-전체-아키텍처-흐름)
3. [Docker Compose 설정 상세](#3-docker-compose-설정-상세)
4. [Oracle LogMiner 설정](#4-oracle-logminer-설정)
5. [Debezium 커넥터 설정](#5-debezium-커넥터-설정)
6. [Kafka 설정](#6-kafka-설정)
7. [Spring Boot 애플리케이션 설정](#7-spring-boot-애플리케이션-설정)
8. [Java 소스코드 상세](#8-java-소스코드-상세)

---

## 1. CDC 개념 이해

### 1.1 CDC란?

**CDC (Change Data Capture)** = 데이터베이스의 변경사항을 실시간으로 캡처하는 기술

```
┌─────────────┐     ┌─────────────┐
│   DB 변경    │ ──► │  CDC 캡처   │ ──► 다른 시스템으로 전달
│ INSERT/UPDATE│     │  (실시간)   │
└─────────────┘     └─────────────┘
```

### 1.2 왜 CDC를 사용하는가?

**전통적 방식 (배치 동기화):**
```
매일 밤 12시에 전체 데이터 비교 → 변경분 추출 → 동기화
문제점: 실시간 아님, 대용량 데이터 비교 부담
```

**CDC 방식:**
```
데이터 변경 즉시 캡처 → 실시간 동기화
장점: 실시간, DB 부하 적음, 변경분만 처리
```

### 1.3 Debezium이란?

**Debezium** = 오픈소스 CDC 플랫폼

- Red Hat에서 개발 (Apache License 2.0)
- 다양한 DB 지원: Oracle, MySQL, PostgreSQL, MongoDB 등
- Kafka Connect 기반으로 동작
- 트랜잭션 로그를 읽어서 변경사항 캡처

**왜 Debezium을 선택했나?**
1. 오픈소스 (무료)
2. Oracle 공식 지원
3. Kafka와 자연스러운 통합
4. 활발한 커뮤니티

---

## 2. 전체 아키텍처 흐름

### 2.1 데이터 흐름도

```
┌─────────────────────────────────────────────────────────────────────────┐
│                           CDC PoC 전체 흐름                              │
└─────────────────────────────────────────────────────────────────────────┘

[STEP 1] 사용자가 ASIS DB에서 UPDATE 실행
         ┌──────────────┐
         │  ASIS Oracle │  UPDATE BOOK_INFO SET BOOK_TITLE = '새제목'
         │   (1521)     │
         └──────┬───────┘
                │
                ▼
[STEP 2] Oracle이 Redo Log에 변경사항 기록 (자동)
         ┌──────────────┐
         │  Redo Log    │  변경 전/후 데이터가 기록됨
         │  (자동)      │
         └──────┬───────┘
                │
                ▼
[STEP 3] Debezium이 LogMiner로 Redo Log 읽기
         ┌──────────────┐
         │  Debezium    │  LogMiner API로 Redo Log 조회
         │  Connector   │  → 변경사항 추출
         └──────┬───────┘
                │
                ▼
[STEP 4] Kafka 토픽에 이벤트 발행
         ┌──────────────┐
         │    Kafka     │  토픽: asis.ASIS_USER.BOOK_INFO
         │   (9092)     │  메시지: { "op": "u", "before": {...}, "after": {...} }
         └──────┬───────┘
                │
                ▼
[STEP 5] Sync Service가 Kafka 메시지 수신
         ┌──────────────┐
         │ Sync Service │  @KafkaListener로 메시지 수신
         │  (Java)      │  → JSON 파싱 → CdcEvent 객체로 변환
         └──────┬───────┘
                │
                ▼
[STEP 6] TOBE DB의 CDC 테이블에 INSERT
         ┌──────────────┐
         │  TOBE Oracle │  INSERT INTO CDC_TOBE_BOOK (...)
         │   (1522)     │  → WORKER 프로시저가 나중에 처리
         └──────────────┘
```

### 2.2 각 컴포넌트의 역할

| 컴포넌트 | 역할 | 비유 |
|---------|------|------|
| Oracle Redo Log | 모든 변경사항 기록 | 은행 거래 장부 |
| Debezium | Redo Log 읽어서 이벤트 생성 | 장부 감시자 |
| Kafka | 이벤트 전달 및 저장 | 우체국 |
| Sync Service | 이벤트 수신 및 처리 | 우편 배달부 |
| CDC 테이블 | 받은 이벤트 임시 저장 | 우편함 |
| WORKER | CDC 테이블 처리 | 우편물 처리자 |

---

## 3. Docker Compose 설정 상세

### 3.1 전체 구조

```yaml
# docker-compose.yml 전체 구조
services:
  asis-oracle:    # ASIS DB (원본 데이터)
  tobe-oracle:    # TOBE DB (대상 데이터)
  zookeeper:      # Kafka 의존성
  kafka:          # 메시지 브로커
  kafka-connect:  # Debezium 실행 환경
  sync-service:   # CDC 이벤트 처리
  kafka-ui:       # 모니터링 UI
```

### 3.2 Oracle 설정 상세

```yaml
asis-oracle:
  image: gvenzl/oracle-xe:21-slim
  # ┗━ gvenzl/oracle-xe: 경량화된 Oracle XE 이미지 (공식보다 가벼움)
  # ┗━ 21-slim: Oracle 21c 버전, slim 태그는 최소 설치

  container_name: asis-oracle
  # ┗━ 컨테이너 이름 지정 (docker logs asis-oracle 등에서 사용)

  environment:
    ORACLE_PASSWORD: oracle123
    # ┗━ SYS/SYSTEM 계정 비밀번호

    APP_USER: asis_user
    APP_USER_PASSWORD: asis123
    # ┗━ 자동 생성되는 애플리케이션 사용자

  ports:
    - "1521:1521"
    # ┗━ 호스트:컨테이너 포트 매핑
    # ┗━ localhost:1521로 접속 가능

  volumes:
    - asis-oracle-data:/opt/oracle/oradata
    # ┗━ 데이터 영속성 (컨테이너 삭제해도 데이터 유지)

    - ./asis-oracle/init:/container-entrypoint-initdb.d
    # ┗━ 초기화 SQL 스크립트 위치
    # ┗━ 컨테이너 첫 시작 시 자동 실행

  networks:
    - cdc-net
    # ┗━ 같은 네트워크의 컨테이너끼리 이름으로 통신 가능
    # ┗━ 예: kafka-connect에서 "asis-oracle:1521"로 접속

  healthcheck:
    test: ["CMD", "healthcheck.sh"]
    interval: 30s      # 30초마다 체크
    timeout: 10s       # 10초 내 응답 없으면 실패
    retries: 10        # 10번 실패하면 unhealthy
    # ┗━ Oracle이 완전히 시작될 때까지 기다림
```

### 3.3 Kafka 설정 상세

```yaml
kafka:
  image: confluentinc/cp-kafka:7.5.0
  # ┗━ Confluent 제공 Kafka 이미지 (가장 널리 사용)

  depends_on:
    - zookeeper
    # ┗━ Zookeeper가 먼저 시작되어야 함

  ports:
    - "9092:9092"    # 외부 접속용 (localhost)
    - "29092:29092"  # 내부 접속용 (Docker 네트워크)

  environment:
    KAFKA_BROKER_ID: 1
    # ┗━ 브로커 고유 ID (클러스터에서 식별용)

    KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    # ┗━ Zookeeper 연결 주소
    # ┗━ Kafka 메타데이터 저장용

    KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
    # ┗━ 클라이언트에게 알려주는 접속 주소
    # ┗━ PLAINTEXT: Docker 내부용 (kafka:29092)
    # ┗━ PLAINTEXT_HOST: 외부용 (localhost:9092)

    KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
    # ┗━ 각 리스너의 보안 프로토콜
    # ┗━ PLAINTEXT = 암호화 없음 (개발용)

    KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    # ┗━ 브로커 간 통신에 사용할 리스너

    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    # ┗━ 오프셋 토픽 복제 개수
    # ┗━ 1 = 단일 브로커 환경 (PoC용)
    # ┗━ 운영환경에서는 3 이상 권장
```

**왜 리스너가 2개인가?**

```
┌─────────────────────────────────────────────────────┐
│                    Docker 환경                       │
│  ┌─────────────┐          ┌─────────────┐          │
│  │ Sync Service│─kafka:29092→│   Kafka   │          │
│  └─────────────┘          └─────────────┘          │
└─────────────────────────────────────────────────────┘
         │                         ▲
         │    localhost:9092       │
         └─────────────────────────┘

- Docker 내부: kafka:29092 (컨테이너 이름으로 접속)
- Docker 외부: localhost:9092 (호스트에서 접속)
```

### 3.4 Kafka Connect (Debezium) 설정 상세

```yaml
kafka-connect:
  image: debezium/connect:2.4
  # ┗━ Debezium 공식 이미지
  # ┗━ Kafka Connect + Debezium 커넥터 포함

  volumes:
    - ./kafka-connect/libs/ojdbc11.jar:/kafka/libs/ojdbc11.jar
    # ┗━ Oracle JDBC 드라이버 추가
    # ┗━ Debezium 이미지에 포함 안 됨 (라이선스 문제)
    # ┗━ Maven Central에서 직접 다운로드 필요

  environment:
    BOOTSTRAP_SERVERS: kafka:29092
    # ┗━ Kafka 접속 주소

    GROUP_ID: cdc-connect-cluster
    # ┗━ Kafka Connect 클러스터 ID

    CONFIG_STORAGE_TOPIC: cdc_connect_configs
    OFFSET_STORAGE_TOPIC: cdc_connect_offsets
    STATUS_STORAGE_TOPIC: cdc_connect_statuses
    # ┗━ Kafka Connect 내부 상태 저장용 토픽
    # ┗━ 커넥터 설정, 오프셋(어디까지 읽었는지), 상태 저장

    KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
    VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
    # ┗━ 메시지 변환기 (JSON 형식 사용)

    KEY_CONVERTER_SCHEMAS_ENABLE: "false"
    VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
    # ┗━ 스키마 정보 포함 여부
    # ┗━ false: 메시지가 더 간결해짐
```

### 3.5 Sync Service 설정 상세

```yaml
sync-service:
  build: ./sync-service-java
  # ┗━ Dockerfile 위치
  # ┗━ 로컬에서 이미지 빌드

  image: poc-sync-service-java
  # ┗━ 빌드된 이미지 이름

  depends_on:
    - kafka
    - asis-oracle
    - tobe-oracle
    # ┗━ 이 서비스들이 먼저 시작되어야 함

  ports:
    - "8082:8080"
    # ┗━ Spring Boot 포트 매핑
    # ┗━ localhost:8082/actuator/health 로 접속

  environment:
    KAFKA_BOOTSTRAP_SERVERS: kafka:29092
    # ┗━ Kafka 접속 주소 (Docker 내부 네트워크)

    ASIS_DB_HOST: asis-oracle
    ASIS_DB_PORT: 1521
    ASIS_DB_SERVICE: XEPDB1
    ASIS_DB_USER: asis_user
    ASIS_DB_PASSWORD: asis123
    # ┗━ ASIS DB 접속 정보
    # ┗━ XEPDB1: Oracle XE의 기본 PDB 이름

    TOBE_DB_HOST: tobe-oracle
    TOBE_DB_PORT: 1521
    TOBE_DB_SERVICE: XEPDB1
    TOBE_DB_USER: tobe_user
    TOBE_DB_PASSWORD: tobe123
    # ┗━ TOBE DB 접속 정보

  healthcheck:
    test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
    # ┗━ Spring Boot Actuator health 엔드포인트 체크

    interval: 30s
    timeout: 10s
    retries: 5
    start_period: 60s
    # ┗━ start_period: 앱 시작 대기 시간
    # ┗━ 60초 동안은 실패해도 unhealthy로 안 바뀜
```

---

## 4. Oracle LogMiner 설정

### 4.1 LogMiner란?

**LogMiner** = Oracle의 Redo Log를 분석하는 기능

```
┌─────────────────────────────────────────┐
│             Oracle Database             │
│  ┌─────────┐    ┌─────────────────────┐ │
│  │ 테이블  │───►│     Redo Log        │ │
│  │ 변경    │    │ (모든 변경 기록)    │ │
│  └─────────┘    └──────────┬──────────┘ │
│                            │            │
│                 ┌──────────▼──────────┐ │
│                 │     LogMiner        │ │
│                 │ (로그 분석 도구)    │ │
│                 └─────────────────────┘ │
└─────────────────────────────────────────┘
```

### 4.2 왜 LogMiner가 필요한가?

**Debezium이 Oracle 변경을 캡처하는 방법:**
1. ~~트리거~~ - 성능 저하, 테이블 수정 필요
2. **LogMiner** - Redo Log 읽기 (무침입적)
3. ~~XStream~~ - 라이선스 필요

**LogMiner 장점:**
- 애플리케이션 코드 수정 불필요
- 기존 테이블 수정 불필요
- 성능 영향 최소화

### 4.3 LogMiner 설정 방법 (상세)

#### 4.3.1 Archive Log 모드 활성화

```sql
-- SYS 권한으로 실행

-- 현재 모드 확인
SELECT LOG_MODE FROM V$DATABASE;
-- 결과: NOARCHIVELOG (기본값)

-- Archive Log 모드로 변경
SHUTDOWN IMMEDIATE;
STARTUP MOUNT;
ALTER DATABASE ARCHIVELOG;
ALTER DATABASE OPEN;

-- 확인
SELECT LOG_MODE FROM V$DATABASE;
-- 결과: ARCHIVELOG
```

**왜 Archive Log 모드가 필요한가?**

```
NOARCHIVELOG 모드:
┌──────────┐  가득 차면  ┌──────────┐
│ Redo Log │────덮어쓰기──►│ Redo Log │ = 과거 데이터 손실
└──────────┘             └──────────┘

ARCHIVELOG 모드:
┌──────────┐  가득 차면  ┌──────────────┐
│ Redo Log │────복사────►│ Archive Log  │ = 과거 데이터 보존
└──────────┘             └──────────────┘
                         (Debezium이 읽을 수 있음)
```

#### 4.3.2 Supplemental Logging 활성화

```sql
-- Supplemental Logging 활성화
ALTER DATABASE ADD SUPPLEMENTAL LOG DATA;
ALTER DATABASE ADD SUPPLEMENTAL LOG DATA (ALL) COLUMNS;
```

**왜 Supplemental Logging이 필요한가?**

기본적으로 Redo Log에는 변경된 컬럼만 기록됨:

```sql
UPDATE BOOK_INFO SET BOOK_TITLE = '새제목' WHERE BOOK_ID = 1;
```

**Supplemental Logging OFF:**
```
Redo Log: { BOOK_TITLE: '새제목' }
문제: 어떤 행이 변경됐는지 모름!
```

**Supplemental Logging ON:**
```
Redo Log: { BOOK_ID: 1, BOOK_TITLE: '새제목', AUTHOR: '홍길동', ... }
모든 컬럼이 기록되어 완전한 정보 확보
```

#### 4.3.3 Debezium 전용 사용자 생성

```sql
-- Common User 생성 (c## 접두사 필수)
CREATE USER c##dbzuser IDENTIFIED BY dbz
    DEFAULT TABLESPACE USERS
    QUOTA UNLIMITED ON USERS
    CONTAINER=ALL;

-- 필수 권한 부여
GRANT CREATE SESSION TO c##dbzuser CONTAINER=ALL;
-- ┗━ DB 접속 권한

GRANT SELECT ON V_$DATABASE TO c##dbzuser CONTAINER=ALL;
GRANT SELECT ON V_$LOG TO c##dbzuser CONTAINER=ALL;
GRANT SELECT ON V_$LOGFILE TO c##dbzuser CONTAINER=ALL;
GRANT SELECT ON V_$ARCHIVED_LOG TO c##dbzuser CONTAINER=ALL;
-- ┗━ Redo Log 메타데이터 조회 권한

GRANT SELECT ON V_$LOGMNR_CONTENTS TO c##dbzuser CONTAINER=ALL;
-- ┗━ LogMiner 결과 조회 권한

GRANT EXECUTE ON DBMS_LOGMNR TO c##dbzuser CONTAINER=ALL;
GRANT EXECUTE ON DBMS_LOGMNR_D TO c##dbzuser CONTAINER=ALL;
-- ┗━ LogMiner 프로시저 실행 권한

GRANT SELECT ANY TABLE TO c##dbzuser CONTAINER=ALL;
GRANT FLASHBACK ANY TABLE TO c##dbzuser CONTAINER=ALL;
-- ┗━ 테이블 데이터 조회 권한

GRANT LOGMINING TO c##dbzuser CONTAINER=ALL;
-- ┗━ LogMiner 사용 권한 (Oracle 12c+)
```

**왜 c## 접두사가 필요한가?**

Oracle 12c부터 CDB/PDB 아키텍처 도입:
```
┌─────────────────────────────────────┐
│            CDB (컨테이너 DB)         │
│  ┌─────────┐  ┌─────────┐          │
│  │ CDB$ROOT│  │  XEPDB1 │ ← PDB    │
│  │(시스템) │  │(사용자) │          │
│  └─────────┘  └─────────┘          │
└─────────────────────────────────────┘

- c## 접두사: CDB 레벨 공통 사용자
- CONTAINER=ALL: 모든 PDB에서 사용 가능
```

---

## 5. Debezium 커넥터 설정

### 5.1 커넥터 등록 방법

```bash
curl -X POST http://localhost:8083/connectors \
  -H "Content-Type: application/json" \
  -d '{
    "name": "asis-oracle-connector",
    "config": {
      ... (설정값)
    }
  }'
```

### 5.2 커넥터 설정 상세

```json
{
  "name": "asis-oracle-connector",
  // ┗━ 커넥터 이름 (고유해야 함)

  "config": {
    "connector.class": "io.debezium.connector.oracle.OracleConnector",
    // ┗━ Debezium Oracle 커넥터 클래스

    "database.hostname": "asis-oracle",
    "database.port": "1521",
    // ┗━ Oracle 접속 정보
    // ┗━ Docker 네트워크 내 컨테이너 이름 사용

    "database.user": "c##dbzuser",
    "database.password": "dbz",
    // ┗━ LogMiner용 사용자 계정

    "database.dbname": "XE",
    // ┗━ CDB 이름 (Oracle XE 기본값)

    "database.pdb.name": "XEPDB1",
    // ┗━ PDB 이름 (실제 데이터가 있는 곳)

    "topic.prefix": "asis",
    // ┗━ Kafka 토픽 접두사
    // ┗━ 결과: asis.ASIS_USER.BOOK_INFO

    "schema.include.list": "ASIS_USER",
    // ┗━ 캡처할 스키마 (사용자) 목록

    "table.include.list": "ASIS_USER.BOOK_INFO,ASIS_USER.MEMBER_INFO,ASIS_USER.LEGACY_CODE",
    // ┗━ 캡처할 테이블 목록
    // ┗━ 형식: 스키마.테이블

    "schema.history.internal.kafka.bootstrap.servers": "kafka:29092",
    "schema.history.internal.kafka.topic": "schema-changes.asis",
    // ┗━ 스키마 변경 이력 저장용 토픽
    // ┗━ DDL 변경 추적

    "log.mining.strategy": "online_catalog"
    // ┗━ LogMiner 전략
    // ┗━ online_catalog: 온라인 딕셔너리 사용 (권장)
  }
}
```

### 5.3 생성되는 Kafka 토픽 구조

```
토픽 이름 규칙: {topic.prefix}.{스키마}.{테이블}

예시:
- asis.ASIS_USER.BOOK_INFO      ← BOOK_INFO 테이블 변경
- asis.ASIS_USER.MEMBER_INFO    ← MEMBER_INFO 테이블 변경
- tobe.TOBE_USER.TB_BOOK        ← TB_BOOK 테이블 변경
```

### 5.4 Debezium 메시지 구조

```json
{
  "schema": { ... },  // 스키마 정보 (생략 가능)

  "payload": {
    "op": "u",        // 작업 유형: c=INSERT, u=UPDATE, d=DELETE, r=스냅샷

    "before": {       // 변경 전 데이터 (UPDATE, DELETE 시)
      "BOOK_ID": {"scale": 0, "value": "AQ=="},
      "BOOK_TITLE": "기존제목",
      ...
    },

    "after": {        // 변경 후 데이터 (INSERT, UPDATE 시)
      "BOOK_ID": {"scale": 0, "value": "AQ=="},
      "BOOK_TITLE": "새제목",
      ...
    },

    "source": {       // 소스 정보
      "version": "2.4.2.Final",
      "connector": "oracle",
      "name": "asis",
      "ts_ms": 1768284010000,       // 변경 발생 시간
      "db": "XEPDB1",
      "schema": "ASIS_USER",
      "table": "BOOK_INFO",
      "scn": "3009564",             // System Change Number
      "user_name": "ASIS_USER"
    },

    "ts_ms": 1768284013301  // Debezium 처리 시간
  }
}
```

### 5.5 Debezium 타입 변환

**NUMBER 타입:**
```json
// Oracle: NUMBER(10)
// Debezium 변환:
{
  "scale": 0,           // 소수점 자릿수
  "value": "AQ=="       // Base64 인코딩된 BigInteger
}

// 디코딩:
Base64.decode("AQ==") → bytes → BigInteger → 1
```

**DATE/TIMESTAMP 타입:**
```json
// Oracle: DATE, TIMESTAMP
// Debezium 변환: epoch milliseconds (Long)
1768279858000  // 2026-01-13 09:30:58 UTC
```

---

## 6. Kafka 설정

### 6.1 주요 개념

```
┌─────────────────────────────────────────────────────────┐
│                      Kafka 구조                          │
│                                                          │
│   Producer ─────► Topic ─────► Consumer                 │
│  (Debezium)      (메시지 저장)  (Sync Service)          │
│                                                          │
│   Topic 내부 구조:                                       │
│   ┌──────────────────────────────────────┐              │
│   │ Partition 0: [msg1] [msg2] [msg3] ...│              │
│   │ Partition 1: [msg4] [msg5] ...       │              │
│   └──────────────────────────────────────┘              │
│                                                          │
│   Consumer Group:                                        │
│   - 같은 그룹의 Consumer끼리 파티션 분담                  │
│   - 각 파티션은 하나의 Consumer만 읽음                   │
└─────────────────────────────────────────────────────────┘
```

### 6.2 중요 설정값

| 설정 | 값 | 의미 |
|------|-----|------|
| `bootstrap-servers` | kafka:29092 | Kafka 브로커 주소 |
| `group-id` | cdc-sync-service | Consumer 그룹 ID |
| `auto-offset-reset` | earliest | 처음부터 읽기 시작 |
| `enable-auto-commit` | true | 오프셋 자동 커밋 |

**auto-offset-reset 옵션:**
```
earliest: 토픽의 처음부터 읽기 (놓친 메시지 없음)
latest: 현재 시점부터 읽기 (과거 메시지 무시)
```

---

## 7. Spring Boot 애플리케이션 설정

### 7.1 application.yml 전체 설명

```yaml
# ==============================================
# 서버 설정
# ==============================================
server:
  port: 8080
  # ┗━ Spring Boot 웹 서버 포트
  # ┗━ Actuator 엔드포인트 제공용

# ==============================================
# Spring 기본 설정
# ==============================================
spring:
  application:
    name: cdc-sync-service
    # ┗━ 애플리케이션 이름 (로그, 모니터링에 표시)

  # Kafka Consumer 설정
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:kafka:29092}
    # ┗━ ${환경변수:기본값} 형식
    # ┗━ 환경변수가 없으면 kafka:29092 사용

    consumer:
      group-id: cdc-sync-service
      # ┗━ Consumer Group ID
      # ┗━ 같은 그룹의 Consumer끼리 메시지 분담

      auto-offset-reset: earliest
      # ┗━ earliest: 토픽의 처음부터 읽기
      # ┗━ latest: 현재 시점부터 읽기

      enable-auto-commit: true
      # ┗━ 오프셋 자동 커밋
      # ┗━ 메시지 처리 후 어디까지 읽었는지 자동 저장

      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # ┗━ 메시지 역직렬화 방식
      # ┗━ String으로 받아서 직접 JSON 파싱

# ==============================================
# 데이터소스 설정
# ==============================================

# ASIS DB 설정
asis:
  datasource:
    jdbc-url: jdbc:oracle:thin:@${ASIS_DB_HOST:asis-oracle}:${ASIS_DB_PORT:1521}/${ASIS_DB_SERVICE:XEPDB1}
    # ┗━ jdbc-url: HikariCP가 인식하는 속성명 (url 아님!)
    # ┗━ thin: Oracle JDBC 드라이버 유형
    # ┗━ @호스트:포트/서비스명 형식

    username: ${ASIS_DB_USER:asis_user}
    password: ${ASIS_DB_PASSWORD:asis123}
    driver-class-name: oracle.jdbc.OracleDriver

    # HikariCP 커넥션 풀 설정
    pool-name: ASIS-Pool
    maximum-pool-size: 5
    # ┗━ 최대 커넥션 수

    minimum-idle: 2
    # ┗━ 유휴 상태 최소 커넥션 수

    connection-timeout: 30000
    # ┗━ 커넥션 획득 타임아웃 (ms)

# TOBE DB 설정 (ASIS와 동일 구조)
tobe:
  datasource:
    jdbc-url: jdbc:oracle:thin:@${TOBE_DB_HOST:tobe-oracle}:${TOBE_DB_PORT:1521}/${TOBE_DB_SERVICE:XEPDB1}
    username: ${TOBE_DB_USER:tobe_user}
    password: ${TOBE_DB_PASSWORD:tobe123}
    driver-class-name: oracle.jdbc.OracleDriver
    pool-name: TOBE-Pool
    maximum-pool-size: 5
    minimum-idle: 2
    connection-timeout: 30000

# ==============================================
# 로깅 설정
# ==============================================
logging:
  level:
    root: INFO
    # ┗━ 기본 로그 레벨

    com.cdc.sync: DEBUG
    # ┗━ 우리 패키지는 DEBUG 레벨 (상세 로그)

    org.springframework.kafka: INFO
    org.apache.kafka: WARN
    # ┗━ Kafka 관련 로그는 간략하게

# ==============================================
# Actuator 설정 (Health Check)
# ==============================================
management:
  endpoints:
    web:
      exposure:
        include: health,info
        # ┗━ 노출할 엔드포인트
        # ┗━ /actuator/health, /actuator/info

  endpoint:
    health:
      show-details: always
      # ┗━ 상세 정보 항상 표시

  health:
    kafka:
      enabled: true
      # ┗━ Kafka 연결 상태 체크

    db:
      enabled: false
      # ┗━ DB 체크 비활성화
      # ┗━ 커스텀 DataSource라서 기본 체크 안 됨
```

---

## 8. Java 소스코드 상세

### 8.1 프로젝트 구조

```
sync-service-java/
├── pom.xml                          # Maven 설정
├── Dockerfile                       # Docker 빌드 설정
└── src/main/java/com/cdc/sync/
    ├── SyncServiceApplication.java  # 메인 클래스
    ├── config/
    │   ├── DataSourceConfig.java    # DB 연결 설정
    │   └── KafkaConfig.java         # Kafka 설정
    ├── consumer/
    │   └── CdcKafkaConsumer.java    # Kafka 메시지 수신
    ├── service/
    │   └── CdcSyncService.java      # 비즈니스 로직
    └── model/
        └── CdcEvent.java            # 데이터 모델
```

### 8.2 pom.xml 의존성 설명

```xml
<!-- Spring Boot 기본 -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter</artifactId>
</dependency>
<!-- ┗━ Spring Boot 핵심 기능 (DI, 설정 등) -->

<!-- 웹 서버 (Actuator용) -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-web</artifactId>
</dependency>
<!-- ┗━ 내장 Tomcat, REST API 지원 -->

<!-- Kafka -->
<dependency>
    <groupId>org.springframework.kafka</groupId>
    <artifactId>spring-kafka</artifactId>
</dependency>
<!-- ┗━ @KafkaListener 등 Kafka 통합 기능 -->

<!-- DB 접속 -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-jdbc</artifactId>
</dependency>
<!-- ┗━ JdbcTemplate, 커넥션 풀 (HikariCP) -->

<!-- Oracle JDBC 드라이버 -->
<dependency>
    <groupId>com.oracle.database.jdbc</groupId>
    <artifactId>ojdbc11</artifactId>
    <version>23.3.0.23.09</version>
</dependency>
<!-- ┗━ Oracle DB 접속용 드라이버 -->

<!-- JSON 처리 -->
<dependency>
    <groupId>com.fasterxml.jackson.core</groupId>
    <artifactId>jackson-databind</artifactId>
</dependency>
<!-- ┗━ JSON 파싱 (ObjectMapper) -->

<!-- Health Check -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
<!-- ┗━ /actuator/health 엔드포인트 제공 -->
```

### 8.3 DataSourceConfig.java 상세

```java
@Configuration
public class DataSourceConfig {

    /**
     * ASIS DB 데이터소스
     *
     * @ConfigurationProperties: application.yml의 asis.datasource.* 값을 자동 바인딩
     * DataSourceBuilder: Spring Boot가 제공하는 DataSource 빌더
     * HikariDataSource: 고성능 커넥션 풀
     */
    @Bean(name = "asisDataSource")
    @ConfigurationProperties(prefix = "asis.datasource")
    public DataSource asisDataSource() {
        return DataSourceBuilder.create()
                .type(HikariDataSource.class)
                .build();
    }

    /**
     * ASIS DB용 JdbcTemplate
     *
     * JdbcTemplate: Spring의 JDBC 헬퍼 클래스
     * - SQL 실행 간소화
     * - 예외 변환 (SQLException → DataAccessException)
     * - 커넥션 관리 자동화
     */
    @Bean(name = "asisJdbcTemplate")
    public JdbcTemplate asisJdbcTemplate(
            @Qualifier("asisDataSource") DataSource dataSource) {
        return new JdbcTemplate(dataSource);
    }

    /**
     * TOBE DB 데이터소스
     *
     * @Primary: 기본 DataSource로 지정
     * - Spring이 DataSource를 주입할 때 이것을 우선 사용
     */
    @Bean(name = "tobeDataSource")
    @Primary
    @ConfigurationProperties(prefix = "tobe.datasource")
    public DataSource tobeDataSource() {
        return DataSourceBuilder.create()
                .type(HikariDataSource.class)
                .build();
    }

    @Bean(name = "tobeJdbcTemplate")
    public JdbcTemplate tobeJdbcTemplate(
            @Qualifier("tobeDataSource") DataSource dataSource) {
        return new JdbcTemplate(dataSource);
    }
}
```

**왜 DataSource가 2개인가?**

```
ASIS DB ←──── asisJdbcTemplate ←──── Sync Service
                                          │
TOBE DB ←──── tobeJdbcTemplate ←──────────┘

- ASIS 이벤트 수신 시: tobeJdbcTemplate로 TOBE DB에 INSERT
- TOBE 이벤트 수신 시: asisJdbcTemplate로 ASIS DB에 INSERT
```

### 8.4 CdcKafkaConsumer.java 상세

```java
@Component
public class CdcKafkaConsumer {

    private static final Logger log = LoggerFactory.getLogger(CdcKafkaConsumer.class);

    private final CdcSyncService syncService;
    private final ObjectMapper objectMapper;

    /**
     * 생성자 주입 (Constructor Injection)
     *
     * Spring이 자동으로 CdcSyncService 빈을 주입
     * 테스트 시 Mock 객체 주입 가능
     */
    public CdcKafkaConsumer(CdcSyncService syncService) {
        this.syncService = syncService;
        this.objectMapper = new ObjectMapper();
    }

    /**
     * ASIS BOOK_INFO 테이블 변경 이벤트 처리
     *
     * @KafkaListener:
     * - topics: 구독할 Kafka 토픽
     * - groupId: Consumer Group ID
     *
     * ConsumerRecord: Kafka 메시지 래퍼
     * - key(): 메시지 키 (PK 등)
     * - value(): 메시지 본문 (JSON 문자열)
     * - offset(): 메시지 오프셋
     * - partition(): 파티션 번호
     */
    @KafkaListener(topics = "asis.ASIS_USER.BOOK_INFO", groupId = "cdc-sync-service")
    public void consumeAsisBookInfo(ConsumerRecord<String, String> record) {
        processAsisEvent(record, "CDC_TOBE_BOOK");
    }

    // ... 다른 리스너들 (같은 패턴)

    /**
     * ASIS 이벤트 처리 공통 메서드
     */
    private void processAsisEvent(ConsumerRecord<String, String> record, String targetTable) {
        try {
            // 1. Debezium JSON 파싱
            CdcEvent event = parseDebeziumMessage(record.value());

            if (event != null) {
                // 2. TOBE DB CDC 테이블에 INSERT
                syncService.syncAsisToTobe(event, targetTable);
            }
        } catch (Exception e) {
            log.error("Failed to process ASIS event for {}: {}", targetTable, e.getMessage(), e);
        }
    }

    /**
     * Debezium 메시지 파싱
     *
     * Debezium 메시지 구조:
     * {
     *   "schema": {...},
     *   "payload": {
     *     "op": "u",
     *     "before": {...},
     *     "after": {...},
     *     "source": {...}
     *   }
     * }
     */
    private CdcEvent parseDebeziumMessage(String message) {
        if (message == null || message.isEmpty()) {
            return null;
        }

        try {
            // JSON → Map 변환
            Map<String, Object> json = objectMapper.readValue(
                    message, new TypeReference<Map<String, Object>>() {});

            // payload 추출
            Map<String, Object> payload = json.containsKey("payload")
                    ? (Map<String, Object>) json.get("payload")
                    : json;

            // CdcEvent 객체 생성
            CdcEvent event = new CdcEvent();

            // 작업 유형 (c=INSERT, u=UPDATE, d=DELETE)
            String op = (String) payload.get("op");
            event.setOperation(CdcEvent.convertOperation(op));

            // before/after 데이터
            event.setBefore((Map<String, Object>) payload.get("before"));
            event.setAfter((Map<String, Object>) payload.get("after"));

            // 소스 정보
            event.setSource((Map<String, Object>) payload.get("source"));

            // 타임스탬프
            Object tsMs = payload.get("ts_ms");
            if (tsMs instanceof Number) {
                event.setSourceTimestamp(
                    CdcEvent.convertTimestamp(((Number) tsMs).longValue()));
            }

            // 해시 생성 (무한루프 방지용)
            Map<String, Object> data = event.getData();
            if (data != null) {
                event.setChangeHash(CdcSyncService.generateHash(data));
            }

            log.debug("Parsed CDC event: {}", event);
            return event;

        } catch (JsonProcessingException e) {
            log.error("Failed to parse Debezium message: {}", e.getMessage());
            return null;
        }
    }
}
```

### 8.5 CdcSyncService.java 상세

```java
@Service
public class CdcSyncService {

    private static final Logger log = LoggerFactory.getLogger(CdcSyncService.class);

    private final JdbcTemplate asisJdbcTemplate;
    private final JdbcTemplate tobeJdbcTemplate;

    /**
     * 생성자 주입
     *
     * @Qualifier: 같은 타입의 빈이 여러 개일 때 특정 빈 지정
     */
    public CdcSyncService(
            @Qualifier("asisJdbcTemplate") JdbcTemplate asisJdbcTemplate,
            @Qualifier("tobeJdbcTemplate") JdbcTemplate tobeJdbcTemplate) {
        this.asisJdbcTemplate = asisJdbcTemplate;
        this.tobeJdbcTemplate = tobeJdbcTemplate;
    }

    /**
     * ASIS → TOBE 동기화
     */
    public void syncAsisToTobe(CdcEvent event, String targetTable) {
        // TOBE DB에 INSERT
        insertToCdcTable(tobeJdbcTemplate, event, targetTable, "ASIS->TOBE");
    }

    /**
     * TOBE → ASIS 동기화
     */
    public void syncTobeToAsis(CdcEvent event, String targetTable) {
        // ASIS DB에 INSERT
        insertToCdcTable(asisJdbcTemplate, event, targetTable, "TOBE->ASIS");
    }

    /**
     * CDC 테이블에 INSERT
     */
    private void insertToCdcTable(JdbcTemplate jdbcTemplate, CdcEvent event,
                                  String targetTable, String direction) {
        try {
            Map<String, Object> data = event.getData();
            if (data == null || data.isEmpty()) {
                log.warn("[{}] Empty data for table: {}", direction, targetTable);
                return;
            }

            // 동적 INSERT SQL 생성
            List<String> columns = new ArrayList<>();
            List<Object> values = new ArrayList<>();

            // 메타 컬럼 추가
            columns.add("OPERATION");
            values.add(event.getOperation());

            columns.add("SOURCE_TIMESTAMP");
            values.add(Timestamp.valueOf(event.getSourceTimestamp()));

            columns.add("CHANGE_HASH");
            values.add(event.getChangeHash());

            columns.add("PROCESSED_YN");
            values.add("N");  // 아직 미처리

            // 데이터 컬럼 추가
            for (Map.Entry<String, Object> entry : data.entrySet()) {
                String key = entry.getKey();
                Object value = entry.getValue();

                // Debezium NUMBER 타입 처리
                if (value instanceof Map) {
                    Map<String, Object> complexValue = (Map<String, Object>) value;
                    if (complexValue.containsKey("value")) {
                        value = decodeDebeziumNumber(complexValue);
                    }
                }

                // DATE/TIMESTAMP 컬럼 처리
                String upperKey = key.toUpperCase();
                if (value instanceof Long || value instanceof Integer) {
                    if (upperKey.contains("DATE") || upperKey.contains("_AT") ||
                        upperKey.contains("TIME") || upperKey.contains("TIMESTAMP")) {
                        value = convertEpochToTimestamp(((Number) value).longValue());
                    }
                }

                columns.add(upperKey);
                values.add(value);
            }

            // SQL 생성
            String columnList = String.join(", ", columns);
            String placeholders = columns.stream().map(c -> "?").collect(Collectors.joining(", "));
            String sql = String.format("INSERT INTO %s (%s) VALUES (%s)",
                    targetTable, columnList, placeholders);

            // 실행
            jdbcTemplate.update(sql, values.toArray());

            log.info("[{}] Inserted into {}: {} - hash={}",
                    direction, targetTable, event.getOperation(),
                    event.getChangeHash().substring(0, 16));

        } catch (Exception e) {
            log.error("[{}] Failed to insert into {}: {}",
                    direction, targetTable, e.getMessage(), e);
        }
    }

    /**
     * Debezium NUMBER 타입 디코딩
     *
     * Debezium은 Oracle NUMBER를 다음 형식으로 전송:
     * { "scale": 0, "value": "AQ==" }
     *
     * value는 Base64로 인코딩된 BigInteger
     */
    private Object decodeDebeziumNumber(Map<String, Object> complexValue) {
        try {
            Object valueObj = complexValue.get("value");
            if (valueObj instanceof String base64Value) {
                // Base64 디코딩
                byte[] bytes = Base64.getDecoder().decode(base64Value);
                BigInteger bigInt = new BigInteger(bytes);

                // scale 적용
                Object scaleObj = complexValue.get("scale");
                int scale = scaleObj != null ? ((Number) scaleObj).intValue() : 0;

                if (scale == 0) {
                    return bigInt.longValue();
                } else {
                    return new BigDecimal(bigInt, scale);
                }
            }
        } catch (Exception e) {
            log.warn("Failed to decode Debezium number: {}", e.getMessage());
        }
        return complexValue;
    }

    /**
     * Epoch 밀리초 → Timestamp 변환
     *
     * Debezium은 Oracle DATE/TIMESTAMP를 epoch milliseconds로 전송
     * Oracle INSERT 시 java.sql.Timestamp로 변환 필요
     */
    private Timestamp convertEpochToTimestamp(long epochMs) {
        return new Timestamp(epochMs);
    }

    /**
     * 데이터 해시 생성 (SHA-256)
     *
     * 무한루프 방지용:
     * 1. ASIS에서 변경 → TOBE로 전송 → 해시 저장
     * 2. WORKER가 TOBE 원본 테이블 UPDATE → Debezium 캡처
     * 3. 해시 비교 → 같으면 자신이 만든 변경이므로 무시
     */
    public static String generateHash(Map<String, Object> data) {
        try {
            MessageDigest digest = MessageDigest.getInstance("SHA-256");
            String dataStr = data.toString();
            byte[] hash = digest.digest(dataStr.getBytes(StandardCharsets.UTF_8));

            // Hex 문자열 변환
            StringBuilder hexString = new StringBuilder();
            for (byte b : hash) {
                String hex = Integer.toHexString(0xff & b);
                if (hex.length() == 1) hexString.append('0');
                hexString.append(hex);
            }
            return hexString.toString();
        } catch (NoSuchAlgorithmException e) {
            throw new RuntimeException("SHA-256 not available", e);
        }
    }
}
```

### 8.6 Dockerfile 상세

```dockerfile
# ===========================================
# Stage 1: 빌드 단계
# ===========================================
FROM maven:3.9-eclipse-temurin-17 AS builder
# ┗━ Maven + JDK 17 이미지
# ┗━ AS builder: 멀티스테이지 빌드의 첫 번째 단계 이름

WORKDIR /app

# 의존성 캐싱을 위해 pom.xml 먼저 복사
COPY pom.xml .
RUN mvn dependency:go-offline -B
# ┗━ 의존성만 먼저 다운로드
# ┗━ 소스 변경 시 이 단계는 캐시됨 (빌드 속도 향상)

# 소스 코드 복사 및 빌드
COPY src ./src
RUN mvn package -DskipTests -B
# ┗━ JAR 파일 생성
# ┗━ -DskipTests: 테스트 스킵 (빌드 속도)

# ===========================================
# Stage 2: 실행 단계
# ===========================================
FROM eclipse-temurin:17-jre
# ┗━ JRE만 포함 (JDK보다 가벼움)

WORKDIR /app

# curl 설치 (healthcheck용)
RUN apt-get update && apt-get install -y --no-install-recommends curl \
    && rm -rf /var/lib/apt/lists/*
# ┗━ --no-install-recommends: 최소 설치
# ┗━ rm -rf /var/lib/apt/lists/*: 캐시 삭제 (이미지 크기 축소)

# 빌드 결과물만 복사
COPY --from=builder /app/target/*.jar app.jar
# ┗━ builder 스테이지에서 JAR만 가져옴
# ┗━ 소스코드, Maven 캐시 등은 최종 이미지에 포함 안 됨

# 환경변수 기본값
ENV KAFKA_BOOTSTRAP_SERVERS=kafka:29092 \
    ASIS_DB_HOST=asis-oracle \
    ...
# ┗━ docker-compose에서 오버라이드 가능

# JVM 옵션
ENV JAVA_OPTS="-Xms256m -Xmx512m -XX:+UseG1GC"
# ┗━ -Xms256m: 초기 힙 크기
# ┗━ -Xmx512m: 최대 힙 크기
# ┗━ -XX:+UseG1GC: G1 가비지 컬렉터 사용

# 포트 노출 (문서화 목적)
EXPOSE 8080

# 헬스체크
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8080/actuator/health || exit 1

# 실행
ENTRYPOINT ["sh", "-c", "java $JAVA_OPTS -jar app.jar"]
# ┗━ sh -c: 환경변수 $JAVA_OPTS 해석을 위해 필요
```

---

## 부록: 용어 사전

| 용어 | 설명 |
|------|------|
| CDC | Change Data Capture - 데이터 변경 캡처 |
| Debezium | 오픈소스 CDC 플랫폼 |
| LogMiner | Oracle의 Redo Log 분석 기능 |
| Redo Log | Oracle의 트랜잭션 로그 |
| Archive Log | Redo Log의 아카이브 복사본 |
| Supplemental Logging | Redo Log에 추가 정보 기록 설정 |
| Kafka | 분산 메시지 큐 시스템 |
| Kafka Connect | Kafka 데이터 통합 프레임워크 |
| Consumer Group | Kafka 메시지를 분담해서 처리하는 Consumer 집합 |
| Offset | Kafka에서 메시지의 위치 (어디까지 읽었는지) |
| HikariCP | 고성능 JDBC 커넥션 풀 |
| JdbcTemplate | Spring의 JDBC 헬퍼 클래스 |
| Actuator | Spring Boot 모니터링/관리 기능 |

---

> **다음 문서:** [13_테스트_및_확인_방법.md](13_테스트_및_확인_방법.md) - 테스트 방법 및 확인 가이드
