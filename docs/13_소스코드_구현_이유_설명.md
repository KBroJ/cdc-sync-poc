# CDC PoC 소스코드 구현 이유 설명

> **이 문서의 목적**: 각 코드가 "왜 이렇게 작성되었는지"를 설명합니다.
>
> "이 코드는 뭘 하는 건가요?" 보다 **"왜 이렇게 했나요?"**에 초점을 맞춥니다.

---

## 목차

1. [Kafka Consumer는 왜 이렇게 만들었나?](#1-kafka-consumer는-왜-이렇게-만들었나)
2. [데이터베이스 연결은 왜 2개인가?](#2-데이터베이스-연결은-왜-2개인가)
3. [Debezium 메시지는 왜 이렇게 복잡한가?](#3-debezium-메시지는-왜-이렇게-복잡한가)
4. [해시(Hash)는 왜 만드나?](#4-해시hash는-왜-만드나)
5. [CDC 테이블은 왜 필요한가?](#5-cdc-테이블은-왜-필요한가)
6. [WORKER는 왜 필요한가?](#6-worker는-왜-필요한가)
7. [application.yml 설정 하나하나 설명](#7-applicationyml-설정-하나하나-설명)

---

## 1. Kafka Consumer는 왜 이렇게 만들었나?

### 1.1 전체 그림

```java
@KafkaListener(topics = "asis.ASIS_USER.BOOK_INFO", groupId = "cdc-sync-service")
public void consumeAsisBookInfo(ConsumerRecord<String, String> record) {
    processAsisEvent(record, "CDC_TOBE_BOOK");
}
```

**이 코드가 하는 일:**
1. `asis.ASIS_USER.BOOK_INFO` 토픽에서 메시지가 오면 자동으로 호출됨
2. 메시지를 받아서 `CDC_TOBE_BOOK` 테이블에 저장하라고 지시

### 1.2 왜 @KafkaListener를 사용하나?

**대안 1: 직접 Kafka API 사용**
```java
// 이렇게 하면 복잡함
KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
consumer.subscribe(Arrays.asList("asis.ASIS_USER.BOOK_INFO"));
while (true) {
    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
    for (ConsumerRecord<String, String> record : records) {
        // 처리
    }
}
```

**대안 2: @KafkaListener 사용 (우리가 선택한 방법)**
```java
@KafkaListener(topics = "asis.ASIS_USER.BOOK_INFO", groupId = "cdc-sync-service")
public void consumeAsisBookInfo(ConsumerRecord<String, String> record) {
    // 처리
}
```

**왜 @KafkaListener를 선택했나?**
- 코드가 훨씬 간단함
- 스레드 관리, 오류 처리 등을 Spring이 알아서 해줌
- 여러 토픽 처리 시 각각 메서드만 추가하면 됨

### 1.3 왜 토픽마다 별도 메서드인가?

```java
@KafkaListener(topics = "asis.ASIS_USER.BOOK_INFO", groupId = "cdc-sync-service")
public void consumeAsisBookInfo(ConsumerRecord<String, String> record) {
    processAsisEvent(record, "CDC_TOBE_BOOK");  // ← TOBE의 CDC_TOBE_BOOK 테이블로
}

@KafkaListener(topics = "asis.ASIS_USER.MEMBER_INFO", groupId = "cdc-sync-service")
public void consumeAsisMemberInfo(ConsumerRecord<String, String> record) {
    processAsisEvent(record, "CDC_TOBE_MEMBER");  // ← TOBE의 CDC_TOBE_MEMBER 테이블로
}
```

**왜 하나의 메서드로 안 하나?**

이론적으로는 가능:
```java
@KafkaListener(topics = {"asis.ASIS_USER.BOOK_INFO", "asis.ASIS_USER.MEMBER_INFO"})
public void consumeAll(ConsumerRecord<String, String> record) {
    String topic = record.topic();
    String targetTable = switch(topic) {
        case "asis.ASIS_USER.BOOK_INFO" -> "CDC_TOBE_BOOK";
        case "asis.ASIS_USER.MEMBER_INFO" -> "CDC_TOBE_MEMBER";
        default -> throw new IllegalStateException();
    };
    processAsisEvent(record, targetTable);
}
```

**하지만 메서드를 분리한 이유:**
1. 코드가 더 명확함 (어떤 토픽이 어떤 테이블로 가는지 한눈에 보임)
2. 나중에 테이블별로 다른 처리가 필요할 수 있음
3. 에러 발생 시 어떤 테이블에서 문제인지 쉽게 알 수 있음

### 1.4 groupId는 왜 필요한가?

```java
@KafkaListener(topics = "...", groupId = "cdc-sync-service")
```

**Consumer Group이 뭔가?**

```
┌─────────────────────────────────────────────────────────┐
│                    Kafka 토픽                            │
│  ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐      │
│  │ M1  │ │ M2  │ │ M3  │ │ M4  │ │ M5  │ │ M6  │      │
│  └─────┘ └─────┘ └─────┘ └─────┘ └─────┘ └─────┘      │
└─────────────────────────────────────────────────────────┘
                        │
         ┌──────────────┼──────────────┐
         ▼              ▼              ▼
    ┌─────────┐   ┌─────────┐   ┌─────────┐
    │Consumer │   │Consumer │   │Consumer │
    │   A-1   │   │   A-2   │   │   A-3   │
    └─────────┘   └─────────┘   └─────────┘
         └──────────────┴──────────────┘
                 Group: "cdc-sync-service"

    → 같은 그룹의 Consumer들은 메시지를 나눠서 처리
    → M1,M2는 A-1이, M3,M4는 A-2가, M5,M6는 A-3이 처리
```

**왜 groupId가 중요한가?**

1. **같은 그룹** = 메시지를 나눠서 처리 (병렬 처리)
2. **다른 그룹** = 같은 메시지를 모두 받음 (복제)

```
Group "cdc-sync-service": M1 → Consumer1
                          M2 → Consumer2  (분산 처리)

Group "audit-logger":     M1 → Consumer3
                          M2 → Consumer3  (모든 메시지 받음)
```

---

## 2. 데이터베이스 연결은 왜 2개인가?

### 2.1 DataSourceConfig 전체 구조

```java
@Configuration
public class DataSourceConfig {

    @Bean(name = "asisDataSource")
    @ConfigurationProperties(prefix = "asis.datasource")
    public DataSource asisDataSource() {
        return DataSourceBuilder.create().type(HikariDataSource.class).build();
    }

    @Bean(name = "tobeDataSource")
    @Primary
    @ConfigurationProperties(prefix = "tobe.datasource")
    public DataSource tobeDataSource() {
        return DataSourceBuilder.create().type(HikariDataSource.class).build();
    }
}
```

### 2.2 왜 DB가 2개 필요한가?

**CDC 동기화의 핵심:**
```
ASIS에서 변경 → TOBE로 전송
TOBE에서 변경 → ASIS로 전송
```

따라서 Sync Service는 **양쪽 DB에 모두 접속**해야 합니다:
- ASIS 이벤트 수신 시 → TOBE DB에 INSERT
- TOBE 이벤트 수신 시 → ASIS DB에 INSERT

### 2.3 왜 @Primary가 tobeDataSource에 있나?

```java
@Bean(name = "tobeDataSource")
@Primary  // ← 이것
```

**Spring에서 DataSource가 필요할 때:**
```java
@Autowired
DataSource dataSource;  // 어떤 DataSource를 주입할까?
```

**@Primary가 없으면:**
→ "DataSource 빈이 2개인데 어떤 걸 주입하라는 거야?" 에러

**@Primary가 있으면:**
→ 명시하지 않으면 @Primary가 붙은 것을 주입

**실제로는 @Qualifier로 명시:**
```java
@Qualifier("asisJdbcTemplate") JdbcTemplate asisJdbcTemplate,
@Qualifier("tobeJdbcTemplate") JdbcTemplate tobeJdbcTemplate
```
→ 항상 명시하므로 @Primary는 "만약을 위한 기본값" 역할

### 2.4 왜 HikariDataSource인가?

```java
DataSourceBuilder.create().type(HikariDataSource.class).build()
```

**HikariCP = 고성능 커넥션 풀**

**커넥션 풀이 뭔가?**
```
커넥션 풀 없이:
요청 → DB 연결 생성 → 쿼리 실행 → 연결 종료
요청 → DB 연결 생성 → 쿼리 실행 → 연결 종료  (매번 연결 생성/종료)

커넥션 풀 사용:
시작 시: [연결1] [연결2] [연결3] [연결4] [연결5] 미리 생성

요청 → [연결1 대여] → 쿼리 실행 → [연결1 반납]
요청 → [연결2 대여] → 쿼리 실행 → [연결2 반납]  (재사용)
```

**왜 HikariCP인가?**
- Spring Boot 기본 커넥션 풀
- 가장 빠른 성능
- 메모리 효율적

---

## 3. Debezium 메시지는 왜 이렇게 복잡한가?

### 3.1 Debezium 메시지 구조

```json
{
  "schema": { ... },
  "payload": {
    "op": "u",
    "before": { "BOOK_ID": 1, "BOOK_TITLE": "기존제목" },
    "after": { "BOOK_ID": 1, "BOOK_TITLE": "새제목" },
    "source": { "table": "BOOK_INFO", "ts_ms": 1768284010000 },
    "ts_ms": 1768284013000
  }
}
```

### 3.2 왜 before/after로 나뉘어 있나?

**UPDATE의 경우:**
```json
"before": { "BOOK_TITLE": "기존제목" },  // 변경 전
"after": { "BOOK_TITLE": "새제목" }       // 변경 후
```

**왜 둘 다 필요한가?**
1. 변경 전 값을 알아야 "어떤 데이터가 변경됐는지" 확인 가능
2. 충돌 감지에 사용 (나중에 양방향 동기화 시)

**작업별 데이터:**
| 작업 | before | after |
|------|--------|-------|
| INSERT | null | 새 데이터 |
| UPDATE | 기존 데이터 | 새 데이터 |
| DELETE | 기존 데이터 | null |

### 3.3 왜 NUMBER 타입이 Base64인가?

**Oracle NUMBER:**
```sql
BOOK_ID NUMBER(10)  -- Oracle에서는 이렇게 정의
```

**Debezium이 전송하는 형식:**
```json
"BOOK_ID": { "scale": 0, "value": "AQ==" }
```

**왜 이렇게 변환하나?**

1. **정밀도 보장**: Oracle NUMBER는 최대 38자리. JavaScript의 number는 15자리만 정확
2. **범위 보장**: Java Long 범위를 초과할 수 있음
3. **소수점 보장**: scale 정보로 정확한 소수점 위치 유지

**우리 코드의 처리:**
```java
private Object decodeDebeziumNumber(Map<String, Object> complexValue) {
    // "AQ==" → bytes → BigInteger → 1
    byte[] bytes = Base64.getDecoder().decode(base64Value);
    BigInteger bigInt = new BigInteger(bytes);

    // scale에 따라 Long 또는 BigDecimal 반환
    if (scale == 0) {
        return bigInt.longValue();
    } else {
        return new BigDecimal(bigInt, scale);
    }
}
```

### 3.4 왜 DATE가 숫자(Long)인가?

**Oracle DATE:**
```sql
REG_DATE DATE  -- 2026-01-13 15:30:00
```

**Debezium이 전송하는 형식:**
```json
"REG_DATE": 1768288200000  // epoch milliseconds
```

**epoch milliseconds가 뭔가?**
= 1970년 1월 1일 00:00:00 UTC 부터 경과한 밀리초

**왜 이렇게 변환하나?**
1. **시간대 독립**: 어느 시간대에서 보든 같은 시점
2. **정렬 용이**: 숫자 비교로 시간 순서 정렬 가능
3. **표준 형식**: 모든 시스템에서 처리 가능

**우리 코드의 처리:**
```java
private Timestamp convertEpochToTimestamp(long epochMs) {
    return new Timestamp(epochMs);
    // 1768288200000 → 2026-01-13 15:30:00
}
```

---

## 4. 해시(Hash)는 왜 만드나?

### 4.1 무한루프 문제

**문제 상황:**
```
1. ASIS에서 BOOK_TITLE 변경
2. → TOBE CDC 테이블에 INSERT
3. → WORKER가 TOBE 원본 테이블 UPDATE
4. → Debezium이 TOBE 변경 감지
5. → ASIS CDC 테이블에 INSERT
6. → WORKER가 ASIS 원본 테이블 UPDATE
7. → Debezium이 ASIS 변경 감지
8. → TOBE CDC 테이블에 INSERT (1번과 같은 상황!)
9. → 무한 반복...
```

### 4.2 해시로 해결

**해시 = 데이터의 "지문"**

```java
public static String generateHash(Map<String, Object> data) {
    MessageDigest digest = MessageDigest.getInstance("SHA-256");
    byte[] hash = digest.digest(data.toString().getBytes());
    // 결과: "9dc2ee7d1354e9b9e82430650105a62d26ea16b28..."
}
```

**같은 데이터 → 항상 같은 해시**
**다른 데이터 → 다른 해시**

### 4.3 해시로 무한루프 방지

```
1. ASIS에서 BOOK_TITLE="새제목" 변경
2. → 해시 생성: "abc123..."
3. → TOBE CDC 테이블에 INSERT (CHANGE_HASH="abc123...")
4. → WORKER가 TOBE 원본 테이블 UPDATE
5. → Debezium이 TOBE 변경 감지 (데이터: BOOK_TITLE="새제목")
6. → 해시 계산: "abc123..." (같은 데이터니까 같은 해시)
7. → "이미 처리한 해시네? → 무시!"
```

**WORKER 프로시저에서의 처리 (예시):**
```sql
-- 이미 처리한 해시인지 확인
SELECT COUNT(*) INTO v_count FROM CDC_SYNC_LOG
WHERE CHANGE_HASH = v_hash;

IF v_count > 0 THEN
    -- 이미 처리함 → 무시
    DELETE FROM CDC_TOBE_BOOK WHERE CDC_SEQ = v_seq;
    RETURN;
END IF;
```

---

## 5. CDC 테이블은 왜 필요한가?

### 5.1 직접 UPDATE하면 안 되나?

**대안 (직접 UPDATE):**
```
Debezium 이벤트 → Sync Service → 바로 TOBE 원본 테이블 UPDATE
```

**문제점:**
1. **스키마 변환**: ASIS와 TOBE의 컬럼명/타입이 다름
   - ASIS: `BOOK_TITLE`, `STATUS='Y'`
   - TOBE: `TITLE`, `IS_ACTIVE=1`
2. **트랜잭션 관리**: 여러 테이블을 함께 업데이트해야 할 수 있음
3. **에러 처리**: 실패 시 재시도가 어려움
4. **감사 로그**: 무엇이 언제 변경됐는지 추적 어려움

### 5.2 CDC 테이블의 역할

```
┌─────────────────────────────────────────────────────┐
│                    CDC 테이블                        │
│  ┌────────────────────────────────────────────┐    │
│  │ CDC_SEQ │ OPERATION │ BOOK_ID │ BOOK_TITLE │... │
│  ├─────────┼───────────┼─────────┼────────────┤    │
│  │ 1       │ UPDATE    │ 1       │ 새제목     │    │
│  │ 2       │ INSERT    │ 4       │ 신규도서   │    │
│  │ 3       │ UPDATE    │ 1       │ 다시변경   │    │  ← 순서대로 쌓임
│  └─────────┴───────────┴─────────┴────────────┘    │
└─────────────────────────────────────────────────────┘
                        │
                        ▼
                   WORKER 처리
                        │
                        ▼
                   원본 테이블
```

**CDC 테이블의 장점:**
1. **순서 보장**: CDC_SEQ로 순서대로 처리
2. **재시도 가능**: 실패 시 다시 처리
3. **감사 추적**: 모든 변경 이력 보존
4. **스키마 변환 분리**: WORKER에서 처리

---

## 6. WORKER는 왜 필요한가?

### 6.1 WORKER의 역할

```
CDC 테이블 → [스키마 변환] → 원본 테이블
```

**예시 변환:**
```
CDC_TOBE_BOOK                      TB_BOOK
─────────────                      ───────
BOOK_ID: 1              →          BOOK_ID: 1
BOOK_TITLE: "새제목"    →          TITLE: "새제목"    (컬럼명 변경)
STATUS: "Y"             →          IS_ACTIVE: 1       (값 변환)
CATEGORY: "01"          →          CATEGORY_CD: "LIT" (코드 변환)
```

### 6.2 왜 Sync Service에서 안 하나?

**대안 (Sync Service에서 변환):**
```java
// 컬럼 매핑
String tobeColumn = switch(asisColumn) {
    case "BOOK_TITLE" -> "TITLE";
    case "STATUS" -> "IS_ACTIVE";
    default -> asisColumn;
};

// 값 변환
Object tobeValue = switch(asisColumn) {
    case "STATUS" -> "Y".equals(value) ? 1 : 0;
    default -> value;
};
```

**문제점:**
1. **매핑 정보 관리**: 171개 테이블의 매핑 정보를 Java 코드에?
2. **변경 시 재배포**: 매핑 변경하려면 Java 다시 빌드
3. **DB 종속성**: 매핑 로직은 DB에 있는 게 자연스러움

**WORKER (DB 프로시저) 장점:**
1. **매핑 테이블 사용**: DB 테이블로 매핑 관리
2. **변경 용이**: 테이블만 수정하면 됨
3. **트랜잭션 통합**: CDC 처리 + 원본 UPDATE를 하나의 트랜잭션으로

---

## 7. application.yml 설정 하나하나 설명

### 7.1 Kafka 설정

```yaml
spring:
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:kafka:29092}
```

**이게 뭔가요?**
- `bootstrap-servers`: Kafka 브로커 주소
- `${환경변수:기본값}`: 환경변수가 있으면 사용, 없으면 기본값

**왜 환경변수를 쓰나요?**
→ Docker 환경에서 주소가 달라질 수 있어서
```yaml
# docker-compose.yml
environment:
  KAFKA_BOOTSTRAP_SERVERS: kafka:29092  # ← 여기서 주입
```

### 7.2 Consumer 설정

```yaml
    consumer:
      group-id: cdc-sync-service
      auto-offset-reset: earliest
      enable-auto-commit: true
```

**group-id:**
- Consumer Group 이름
- 같은 그룹끼리 메시지 분담

**auto-offset-reset:**
- `earliest`: 토픽의 처음부터 읽기
- `latest`: 현재 시점부터 읽기
- **왜 earliest인가?** → 놓친 메시지 없이 모두 처리하기 위해

**enable-auto-commit:**
- `true`: 메시지 처리 후 자동으로 "여기까지 읽었다" 기록
- `false`: 수동으로 커밋해야 함 (더 정밀한 제어)
- **왜 true인가?** → PoC에서는 간단하게

### 7.3 DataSource 설정

```yaml
asis:
  datasource:
    jdbc-url: jdbc:oracle:thin:@${ASIS_DB_HOST:asis-oracle}:${ASIS_DB_PORT:1521}/${ASIS_DB_SERVICE:XEPDB1}
```

**jdbc-url vs url:**
```yaml
# 틀림 (HikariCP에서 인식 안 됨)
url: jdbc:oracle:thin:@...

# 맞음 (HikariCP가 인식)
jdbc-url: jdbc:oracle:thin:@...
```
→ HikariCP 사용 시 반드시 `jdbc-url` 사용!

**URL 분석:**
```
jdbc:oracle:thin:@asis-oracle:1521/XEPDB1
│    │      │    │           │    │
│    │      │    │           │    └─ 서비스명 (PDB 이름)
│    │      │    │           └─ 포트
│    │      │    └─ 호스트 (Docker 컨테이너 이름)
│    │      └─ 드라이버 유형 (thin = Type 4 JDBC)
│    └─ DBMS 종류
└─ JDBC 프로토콜
```

### 7.4 커넥션 풀 설정

```yaml
    pool-name: ASIS-Pool
    maximum-pool-size: 5
    minimum-idle: 2
    connection-timeout: 30000
```

**maximum-pool-size: 5**
- 최대 5개 연결 유지
- 왜 5개? → PoC 환경에서 충분한 수

**minimum-idle: 2**
- 최소 2개 연결 항상 유지
- 왜? → 요청 시 바로 사용 가능

**connection-timeout: 30000**
- 30초 내 연결 못 얻으면 에러
- 왜 30초? → Oracle이 느릴 수 있어서 여유 있게

### 7.5 Actuator 설정

```yaml
management:
  endpoints:
    web:
      exposure:
        include: health,info
```

**이게 뭔가요?**
- Spring Boot Actuator = 모니터링/관리 기능
- `/actuator/health` 엔드포인트 활성화

**왜 필요한가요?**
```yaml
# docker-compose.yml
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost:8080/actuator/health"]
```
→ Docker가 서비스 상태를 확인하기 위해

**health 응답 예시:**
```json
{
  "status": "UP",
  "components": {
    "kafka": { "status": "UP" },
    "ping": { "status": "UP" }
  }
}
```

---

## 부록: 자주 하는 질문

### Q1: 왜 Java로 만들었나요? Python이 더 쉽지 않나요?

**최초에는 Python으로 만들었습니다:**
```python
from kafka import KafkaConsumer
consumer = KafkaConsumer('asis.ASIS_USER.BOOK_INFO')
for message in consumer:
    process(message)
```

**Java로 바꾼 이유:**
1. **팀 기술 스택**: 대부분의 팀원이 Java 개발자
2. **운영 환경**: 기존 시스템이 Java/Spring 기반
3. **라이브러리 지원**: Oracle JDBC, Spring Kafka 등 성숙한 생태계
4. **IDE 지원**: IntelliJ에서 디버깅, 리팩토링 등 편리

### Q2: Kafka 대신 다른 거 쓰면 안 되나요?

**대안들:**
- RabbitMQ: 더 간단하지만 대용량 처리에 약함
- ActiveMQ: 레거시 시스템에서 많이 사용
- Redis Pub/Sub: 메시지 보관 안 됨

**Kafka를 선택한 이유:**
1. **Debezium이 Kafka 기반**: 가장 자연스러운 조합
2. **메시지 보관**: 장애 시 재처리 가능
3. **확장성**: 대용량 처리에 강함
4. **커뮤니티**: 자료와 지원이 풍부

### Q3: 왜 원본 테이블을 직접 안 건드리나요?

**제약조건:**
> "기존 CLIMS 테이블 컬럼 추가 불가, 기존 소스 수정 불가"

**따라서:**
- 원본 테이블은 그대로 두고
- CDC 테이블을 별도로 생성
- WORKER가 CDC 테이블 → 원본 테이블 처리

---

> **이 문서가 도움이 되셨나요?**
>
> 더 궁금한 점이 있으면 추가 문서를 작성하겠습니다!
